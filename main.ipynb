{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import sys\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "get_ipython().system = os.system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "GPU_ID=0\n",
    "NUM_THREAD = 8\n",
    "N=100\n",
    "A2C_NAME='1201_512'\n",
    "A2C_T=15000000\n",
    "\n",
    "NUM_SEED = 1 #100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "META_DIR_PATH = './data/meta_models'\n",
    "ENCODER_DIR_PATH = '{}/encoder'.format(META_DIR_PATH)\n",
    "DATASET_PATH = './data/records/{}.pickle.gzip'.format(A2C_T)\n",
    "\n",
    "os.environ['GPU_ID'] = str(GPU_ID)\n",
    "os.environ['N'] = str(N)\n",
    "os.environ['GPU_ID'] = str(GPU_ID)\n",
    "os.environ['A2C_NAME'] = str(A2C_NAME)\n",
    "os.environ['A2C_T'] = str(A2C_T)\n",
    "os.environ['META_DIR_PATH'] = str(META_DIR_PATH)\n",
    "os.environ['ENCODER_DIR_PATH'] = str(ENCODER_DIR_PATH)\n",
    "os.environ['DATASET_PATH'] = str(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training and evaluating Encoder and Manifestor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for seed in range(NUM_SEED):\n",
    "    !bash ./train_encoder.sh\n",
    "    for mapping in '012 021 102 120 201 210'.split():\n",
    "        os.environ['ENCODER_SEED'] = str(seed)\n",
    "        os.environ['MODEL_SEED'] = str(seed + 1000)\n",
    "        os.environ['MAPPING'] = mapping\n",
    "        !bash ./train_meta.sh Manifestor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Fig. 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.exp(x).sum(axis=1, keepdims=True)\n",
    "\n",
    "def calc_loss2(g2, r, match_rate):\n",
    "    cross_entropy_all = list()\n",
    "    match_rate_all = list()\n",
    "    for g2_epi, r_epi, match_epi in zip(g2, r, match_rate):\n",
    "        # calc loss (normalized cross entropy)\n",
    "        match_epi = np.array(match_epi)\n",
    "        r_epi = np.array([r_epi[:, i:i+100].sum(axis=1)/20 for i in range(match_epi.shape[0])])\n",
    "        g0_epi = softmax(r_epi)\n",
    "        nll = -np.log(g2_epi)\n",
    "        cross_entropy = nll * g0_epi\n",
    "\n",
    "        cross_entropy_all.append(cross_entropy)\n",
    "        match_rate_all.append(match_epi)\n",
    "    cross_entropy_all = np.vstack(cross_entropy_all)\n",
    "    match_rate_all = np.hstack(match_rate_all)\n",
    "\n",
    "    loss = cross_entropy_all.sum(axis=1) / cross_entropy_all.sum()\n",
    "    loss *= match_rate_all\n",
    "    loss /= match_rate_all.sum()\n",
    "    return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('./data/meta_models/goal_loss'.format(A2C_T))\n",
    "def process(seed):\n",
    "    translaters = '012 021 102 120 201 210'.split()\n",
    "    results_in_seed = dict()\n",
    "    accuracies = dict()\n",
    "    for translater in translaters:\n",
    "        with (DATA_DIR/'{}_{}.json'.format(seed, translater)).open() as f:\n",
    "            data_original = json.load(f)\n",
    "        data =  {key: np.array([line[key] for line in data_original]) for key in ['g0','g1', 'g2', 'r_']}\n",
    "        data['match_rate'] = [line['match_rate'] for line in data_original]\n",
    "        results_in_seed[translater] = data\n",
    "        accuracies[translater] = (data['g1'].reshape(-1) == data['g2'].reshape((-1, 3)).argmax(axis=1)).mean()\n",
    "        \n",
    "    best_mapping, best_accuracy = max(accuracies.items(), key = lambda x:x[1])\n",
    "    # for debug only\n",
    "    # return best_mapping\n",
    "    trans = str.maketrans({num: char for char, num in zip('ABC', best_mapping)})\n",
    "\n",
    "    losses = dict()\n",
    "    for translater, data in results_in_seed.items():\n",
    "        order = translater.translate(trans)\n",
    "        loss = calc_loss2(data['g2'], data['r_'], data['match_rate'])\n",
    "        losses[order] = loss\n",
    "    ratio = np.array([losses[key] / losses['ABC'] for key in 'ACB BAC BCA CAB CBA'.split()])\n",
    "    n_win = (ratio > 1).sum()\n",
    "    return n_win, ratio, best_accuracy, best_mapping\n",
    "\n",
    "with Pool(NUM_THREAD) as p:\n",
    "    rtn = p.map(process, range(NUM_SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0\n",
    "n_win = [l[0] for l in rtn if l is not None]\n",
    "ratios = [l[1] for l in rtn if l is not None]\n",
    "accuracies = [l[2] for l in rtn if l is not None]\n",
    "best_mappings = [l[3] for l in rtn if l is not None]\n",
    "assert len(n_win) == NUM_SEED\n",
    "\n",
    "with (Path(META_DIR_PATH)/'best_mappings.txt').open('w') as f:\n",
    "    f.write(' '.join(best_mappings))\n",
    "\n",
    "n_total = len(ratios) * 5\n",
    "\n",
    "ratios = np.array(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(MyEncoder, self).default(obj)\n",
    "print(ratios.argsort(axis=1).argsort(axis=1).mean(axis=0) + 1)\n",
    "print(ratios.mean(axis=0))\n",
    "print(ratios.min(axis=0))\n",
    "print(ratios.max(axis=0))\n",
    "\n",
    "statistics = dict(\n",
    "    threshold=threshold,\n",
    "    n_win=sum(n_win),\n",
    "    n_total=n_total,\n",
    "    percentage=sum(n_win)/n_total,\n",
    "    min=ratios.min(),\n",
    "    max=ratios.max(),\n",
    "    mean=ratios.mean(),\n",
    "    std=ratios.std(),\n",
    "    median=np.median(ratios)\n",
    ")\n",
    "print(statistics)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist([ratios[ratios<1], ratios[ratios>=1]], histtype='barstacked', bins=np.arange(0.8, 1.55, 0.005),  ec='white', color=['tab:red','tab:blue'])\n",
    "plt.xlabel('Ratio')\n",
    "plt.ylabel('Density')\n",
    "plt.savefig(DATA_DIR/'hist_{}.pdf'.format(A2C_T))\n",
    "with (DATA_DIR/'hist_{}_stats.json'.format(A2C_T)).open('w') as f:\n",
    "    json.dump(statistics, f, cls=MyEncoder)\n",
    "\n",
    "scipy.stats.norm.interval(alpha=.95, loc=ratios.mean(), scale=ratios.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING ablation and optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for seed, mapping in zip(range(NUM_SEED), best_mappings):\n",
    "    os.environ['ENCODER_SEED'] = str(seed)\n",
    "    os.environ['MODEL_SEED'] = str(seed + 1000)\n",
    "    os.environ['MAPPING'] = mapping\n",
    "    !bash ./train_meta.sh ablation\n",
    "    !bash ./train_meta.sh optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Fig. 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OPTIMAL = 5\n",
    "optimals = sorted((Path(META_DIR_PATH)/'optimal').glob('*'), key=lambda p: int(p.name))[:NUM_OPTIMAL]\n",
    "optimals = [str(list(p.glob('**/Transformer_state_seqlast19.pt'))[0]) for p in optimals]\n",
    "\n",
    "os.environ['TEACHER_PATHS'] = ';'.join(optimals)\n",
    "for seed, mapping in zip(range(NUM_SEED), best_mappings):\n",
    "    os.environ['ENCODER_SEED'] = str(seed)\n",
    "    os.environ['MODEL_SEED'] = str(seed + 1000)\n",
    "    os.environ['MAPPING'] = mapping\n",
    "        \n",
    "    !bash ./eval_meta.sh Manifestor\n",
    "    !bash ./eval_meta.sh ablation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(target):\n",
    "    assert target in ['ablation', 'Manifestor']\n",
    "    comparison_data_dir = Path(META_DIR_PATH)/target/'comparison'\n",
    "    data = [np.load(comparison_data_dir/'{}_{}.npz'.format(i, mapping)) for i, mapping in enumerate(best_mappings)]\n",
    "    return data\n",
    "\n",
    "def calc_acc(ys, ts):\n",
    "    t_labels = ts.mean(axis=1).argmax(axis=1)\n",
    "    y_labels = ys.argmax(axis=1)\n",
    "    n = ys.shape[0]\n",
    "    return (t_labels == y_labels).sum() / n\n",
    "\n",
    "acc_manifestor = np.array([calc_acc(**line) for line in load_data('Manifestor')])\n",
    "acc_ablation = np.array([calc_acc(**line) for line in load_data('ablation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data('Manifestor')[0]['ys'], load_data('Manifestor')[0]['ts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(l):\n",
    "    print(\n",
    "        l.mean(),\n",
    "        l.std(),\n",
    "        l.min(),\n",
    "        l.max(),\n",
    "        np.median(l)\n",
    "    )\n",
    "\n",
    "print_stats(acc_ablation)\n",
    "print_stats(acc_manifestor)\n",
    "print(scipy.stats.mannwhitneyu(acc_ablation, acc_manifestor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,4))\n",
    "df = pd.DataFrame(\n",
    "    \n",
    "    [['manifestor', line] for line in acc_manifestor] + [['ablation', line] for line in acc_ablation],\n",
    "    columns=['type', 'accuracy'])\n",
    "palette=(sns.color_palette()[0], sns.color_palette()[2])\n",
    "sns.boxenplot(x='type', y='accuracy', data=df, ax=ax, palette=palette)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_ylim([0.25,0.97])\n",
    "ax.set_xlabel('')\n",
    "ax.set_xticklabels(['Manifestor', 'Ablation'])\n",
    "plt.savefig('{}/B-2.pdf'.format(META_DIR_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scipy.stats.norm.interval(alpha=.95, loc=acc_manifestor.mean(), scale=acc_manifestor.std()))\n",
    "print(scipy.stats.norm.interval(alpha=.95, loc=acc_ablation.mean(), scale=acc_ablation.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
